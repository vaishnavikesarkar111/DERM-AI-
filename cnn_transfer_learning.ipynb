{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kadam\\Downloads\\Derm-Ai (2) (1)\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\kadam\\Downloads\\Derm-Ai (2) (1)\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.4383 - loss: 1.2389 - val_accuracy: 0.6340 - val_loss: 0.8451\n",
      "Epoch 2/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6562 - loss: 0.8594 - val_accuracy: 0.5237 - val_loss: 0.9163\n",
      "Epoch 3/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6140 - loss: 0.8595 - val_accuracy: 0.6937 - val_loss: 0.6722\n",
      "Epoch 4/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6799 - loss: 0.7920 - val_accuracy: 0.7014 - val_loss: 0.6693\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.6940 - loss: 0.7566 - val_accuracy: 0.7060 - val_loss: 0.6681\n",
      "Epoch 6/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.6692 - loss: 0.7542 - val_accuracy: 0.6983 - val_loss: 0.6300\n",
      "Epoch 7/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7037 - loss: 0.7150 - val_accuracy: 0.7029 - val_loss: 0.6065\n",
      "Epoch 8/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7130 - loss: 0.6749 - val_accuracy: 0.6493 - val_loss: 0.6744\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.6876 - loss: 0.7309 - val_accuracy: 0.6845 - val_loss: 0.6413\n",
      "Epoch 10/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7209 - loss: 0.6603 - val_accuracy: 0.7228 - val_loss: 0.6090\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7151 - loss: 0.6705 - val_accuracy: 0.7198 - val_loss: 0.5815\n",
      "Epoch 12/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7034 - loss: 0.7193 - val_accuracy: 0.7167 - val_loss: 0.6216\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.7323 - loss: 0.6447 - val_accuracy: 0.7289 - val_loss: 0.5508\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.7313 - loss: 0.6338 - val_accuracy: 0.7014 - val_loss: 0.6480\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7395 - loss: 0.6297 - val_accuracy: 0.7397 - val_loss: 0.5542\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7346 - loss: 0.6142 - val_accuracy: 0.7182 - val_loss: 0.5937\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7164 - loss: 0.6802 - val_accuracy: 0.7228 - val_loss: 0.5997\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7447 - loss: 0.6120 - val_accuracy: 0.7443 - val_loss: 0.5436\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7296 - loss: 0.6238 - val_accuracy: 0.7152 - val_loss: 0.6131\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.7640 - loss: 0.5880 - val_accuracy: 0.7473 - val_loss: 0.5620\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.7306 - loss: 0.6421 - val_accuracy: 0.7259 - val_loss: 0.5616\n",
      "Epoch 22/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7340 - loss: 0.6182 - val_accuracy: 0.7427 - val_loss: 0.5556\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7431 - loss: 0.6124 - val_accuracy: 0.7519 - val_loss: 0.5329\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7571 - loss: 0.5602 - val_accuracy: 0.7289 - val_loss: 0.5871\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7591 - loss: 0.5727 - val_accuracy: 0.7473 - val_loss: 0.5641\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7316 - loss: 0.5910 - val_accuracy: 0.7688 - val_loss: 0.5080\n",
      "Epoch 27/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7628 - loss: 0.5859 - val_accuracy: 0.7427 - val_loss: 0.5196\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7594 - loss: 0.5869 - val_accuracy: 0.7688 - val_loss: 0.5338\n",
      "Epoch 29/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7542 - loss: 0.5821 - val_accuracy: 0.7642 - val_loss: 0.5319\n",
      "Epoch 30/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7567 - loss: 0.5700 - val_accuracy: 0.7412 - val_loss: 0.5829\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7601 - loss: 0.5609 - val_accuracy: 0.7504 - val_loss: 0.5485\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7658 - loss: 0.5509 - val_accuracy: 0.7657 - val_loss: 0.5604\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7658 - loss: 0.5769 - val_accuracy: 0.7642 - val_loss: 0.4952\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7524 - loss: 0.5559 - val_accuracy: 0.7795 - val_loss: 0.5257\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.7787 - loss: 0.5284 - val_accuracy: 0.7672 - val_loss: 0.5330\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7890 - loss: 0.5225 - val_accuracy: 0.7749 - val_loss: 0.5407\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7784 - loss: 0.5227 - val_accuracy: 0.7841 - val_loss: 0.4873\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.7919 - loss: 0.5146 - val_accuracy: 0.7657 - val_loss: 0.5136\n",
      "Epoch 39/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7945 - loss: 0.5199 - val_accuracy: 0.7795 - val_loss: 0.4880\n",
      "Epoch 40/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.7668 - loss: 0.5236 - val_accuracy: 0.7979 - val_loss: 0.4640\n",
      "Epoch 41/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7761 - loss: 0.5223 - val_accuracy: 0.7917 - val_loss: 0.4987\n",
      "Epoch 42/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7540 - loss: 0.5398 - val_accuracy: 0.7979 - val_loss: 0.4383\n",
      "Epoch 43/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.7698 - loss: 0.5402 - val_accuracy: 0.7795 - val_loss: 0.5010\n",
      "Epoch 44/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7799 - loss: 0.5288 - val_accuracy: 0.7688 - val_loss: 0.5445\n",
      "Epoch 45/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7694 - loss: 0.5234 - val_accuracy: 0.7795 - val_loss: 0.5091\n",
      "Epoch 46/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7708 - loss: 0.5313 - val_accuracy: 0.7810 - val_loss: 0.5183\n",
      "Epoch 47/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8084 - loss: 0.4679 - val_accuracy: 0.7381 - val_loss: 0.5403\n",
      "Epoch 48/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7797 - loss: 0.5042 - val_accuracy: 0.7933 - val_loss: 0.4909\n",
      "Epoch 49/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8009 - loss: 0.4737 - val_accuracy: 0.7917 - val_loss: 0.4877\n",
      "Epoch 50/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8075 - loss: 0.4755 - val_accuracy: 0.7611 - val_loss: 0.5570\n",
      "Epoch 51/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7923 - loss: 0.4715 - val_accuracy: 0.8070 - val_loss: 0.4728\n",
      "Epoch 52/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7725 - loss: 0.5308 - val_accuracy: 0.7749 - val_loss: 0.5312\n",
      "Epoch 53/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7918 - loss: 0.4707 - val_accuracy: 0.7718 - val_loss: 0.5058\n",
      "Epoch 54/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7978 - loss: 0.4842 - val_accuracy: 0.7320 - val_loss: 0.6175\n",
      "Epoch 55/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8015 - loss: 0.4886 - val_accuracy: 0.7979 - val_loss: 0.4391\n",
      "Epoch 56/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.7959 - loss: 0.4761 - val_accuracy: 0.7458 - val_loss: 0.5867\n",
      "Epoch 57/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.7777 - loss: 0.5013 - val_accuracy: 0.7948 - val_loss: 0.4436\n",
      "Epoch 58/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.8073 - loss: 0.4745 - val_accuracy: 0.7917 - val_loss: 0.5107\n",
      "Epoch 59/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8127 - loss: 0.4469 - val_accuracy: 0.8132 - val_loss: 0.4283\n",
      "Epoch 60/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8012 - loss: 0.4422 - val_accuracy: 0.7994 - val_loss: 0.4710\n",
      "Epoch 61/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8021 - loss: 0.4596 - val_accuracy: 0.8025 - val_loss: 0.4543\n",
      "Epoch 62/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8189 - loss: 0.4579 - val_accuracy: 0.7825 - val_loss: 0.5330\n",
      "Epoch 63/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.7849 - loss: 0.4597 - val_accuracy: 0.7795 - val_loss: 0.5125\n",
      "Epoch 64/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7966 - loss: 0.4622 - val_accuracy: 0.7856 - val_loss: 0.4541\n",
      "Epoch 65/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8180 - loss: 0.4482 - val_accuracy: 0.8086 - val_loss: 0.4141\n",
      "Epoch 66/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8140 - loss: 0.4220 - val_accuracy: 0.7979 - val_loss: 0.4744\n",
      "Epoch 67/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7982 - loss: 0.4690 - val_accuracy: 0.7841 - val_loss: 0.4713\n",
      "Epoch 68/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7977 - loss: 0.4936 - val_accuracy: 0.7810 - val_loss: 0.4325\n",
      "Epoch 69/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8169 - loss: 0.4484 - val_accuracy: 0.8178 - val_loss: 0.4494\n",
      "Epoch 70/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8150 - loss: 0.4144 - val_accuracy: 0.7887 - val_loss: 0.4986\n",
      "Epoch 71/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7954 - loss: 0.4567 - val_accuracy: 0.7795 - val_loss: 0.5095\n",
      "Epoch 72/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8285 - loss: 0.4052 - val_accuracy: 0.7979 - val_loss: 0.4268\n",
      "Epoch 73/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8162 - loss: 0.4185 - val_accuracy: 0.7871 - val_loss: 0.5359\n",
      "Epoch 74/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8272 - loss: 0.4198 - val_accuracy: 0.8147 - val_loss: 0.4434\n",
      "Epoch 75/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8183 - loss: 0.4163 - val_accuracy: 0.8086 - val_loss: 0.4419\n",
      "Epoch 76/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8120 - loss: 0.4755 - val_accuracy: 0.7917 - val_loss: 0.4806\n",
      "Epoch 77/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7960 - loss: 0.4803 - val_accuracy: 0.8239 - val_loss: 0.4354\n",
      "Epoch 78/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8111 - loss: 0.4441 - val_accuracy: 0.7933 - val_loss: 0.4918\n",
      "Epoch 79/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.8133 - loss: 0.4582 - val_accuracy: 0.8025 - val_loss: 0.4816\n",
      "Epoch 80/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.8198 - loss: 0.4307 - val_accuracy: 0.7933 - val_loss: 0.4950\n",
      "Epoch 81/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8101 - loss: 0.4333 - val_accuracy: 0.8178 - val_loss: 0.4520\n",
      "Epoch 82/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8226 - loss: 0.4168 - val_accuracy: 0.8055 - val_loss: 0.4756\n",
      "Epoch 83/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8182 - loss: 0.4501 - val_accuracy: 0.8040 - val_loss: 0.4617\n",
      "Epoch 84/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8238 - loss: 0.4027 - val_accuracy: 0.8025 - val_loss: 0.4786\n",
      "Epoch 85/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8285 - loss: 0.4028 - val_accuracy: 0.7841 - val_loss: 0.5466\n",
      "Epoch 86/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8218 - loss: 0.4055 - val_accuracy: 0.7703 - val_loss: 0.5636\n",
      "Epoch 87/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.8286 - loss: 0.4171 - val_accuracy: 0.7994 - val_loss: 0.5001\n",
      "Epoch 88/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8239 - loss: 0.4070 - val_accuracy: 0.7933 - val_loss: 0.5082\n",
      "Epoch 89/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8100 - loss: 0.4404 - val_accuracy: 0.8116 - val_loss: 0.4645\n",
      "Epoch 90/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8263 - loss: 0.4047 - val_accuracy: 0.8055 - val_loss: 0.4264\n",
      "Epoch 91/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8402 - loss: 0.3952 - val_accuracy: 0.8025 - val_loss: 0.4616\n",
      "Epoch 92/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8194 - loss: 0.4327 - val_accuracy: 0.8055 - val_loss: 0.4663\n",
      "Epoch 93/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8097 - loss: 0.4601 - val_accuracy: 0.8178 - val_loss: 0.4630\n",
      "Epoch 94/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8202 - loss: 0.4530 - val_accuracy: 0.7979 - val_loss: 0.5195\n",
      "Epoch 95/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8294 - loss: 0.4189 - val_accuracy: 0.8377 - val_loss: 0.4102\n",
      "Epoch 96/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8349 - loss: 0.3843 - val_accuracy: 0.8025 - val_loss: 0.4916\n",
      "Epoch 97/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8237 - loss: 0.4044 - val_accuracy: 0.8116 - val_loss: 0.4455\n",
      "Epoch 98/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8365 - loss: 0.3966 - val_accuracy: 0.8285 - val_loss: 0.4177\n",
      "Epoch 99/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.8388 - loss: 0.3720 - val_accuracy: 0.8070 - val_loss: 0.4828\n",
      "Epoch 100/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8349 - loss: 0.3757 - val_accuracy: 0.8086 - val_loss: 0.5370\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8241 - loss: 0.5120\n",
      "Test accuracy: 0.8085758090019226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Step 1: Prepare your dataset\n",
    "image_dir = 'C:/DERM-AI PROJECT/Disease_Dataset_5_classes/train'\n",
    "class_names = os.listdir(image_dir)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Step 2: Load and preprocess the dataset\n",
    "images = []\n",
    "labels = []\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(image_dir, class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(class_dir, filename))\n",
    "            img = cv2.resize(img, (64, 64))  # Resize images to a fixed size\n",
    "            img = img / 255.0  # Normalize pixel values\n",
    "            images.append(img)\n",
    "            labels.append(class_names.index(class_name))\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Step 3: Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Apply image augmentation\n",
    "# Data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,          # Randomly rotate images by 30 degrees\n",
    "    width_shift_range=0.2,      # Shift images horizontally by 20%\n",
    "    height_shift_range=0.2,     # Shift images vertically by 20%\n",
    "    shear_range=0.2,            # Shear transformation\n",
    "    zoom_range=0.2,             # Random zoom\n",
    "    horizontal_flip=True,       # Flip images horizontally\n",
    "    fill_mode='nearest'         # Fill missing pixels with nearest values\n",
    ")\n",
    "\n",
    "# Fit the augmentation generator to the training dataset\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Step 5: Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 6: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Train the model using the augmented data\n",
    "# Use the datagen.flow function to train with augmented images\n",
    "model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "          epochs=100,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('trained_model_with_augmentation.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3265 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kadam\\Downloads\\Derm-Ai (2) (1)\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 793ms/step - accuracy: 0.2263 - loss: 2.7486 - learning_rate: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kadam\\Downloads\\Derm-Ai (2) (1)\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:155: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "c:\\Users\\kadam\\Downloads\\Derm-Ai (2) (1)\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:151: UserWarning: Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n",
      "c:\\Users\\kadam\\Downloads\\Derm-Ai (2) (1)\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:206: UserWarning: Can save best model only with val_accuracy available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 814ms/step - accuracy: 0.3817 - loss: 1.9469 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 801ms/step - accuracy: 0.3863 - loss: 1.8113 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.4132 - loss: 1.7014 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 795ms/step - accuracy: 0.4239 - loss: 1.6504 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 799ms/step - accuracy: 0.4150 - loss: 1.5929 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 801ms/step - accuracy: 0.4322 - loss: 1.5663 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 790ms/step - accuracy: 0.4256 - loss: 1.5260 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 794ms/step - accuracy: 0.4081 - loss: 1.5105 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.4292 - loss: 1.4777 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 789ms/step - accuracy: 0.4189 - loss: 1.4717 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 4s/step - accuracy: 0.4207 - loss: 1.4259 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 792ms/step - accuracy: 0.4222 - loss: 1.4314 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 795ms/step - accuracy: 0.4081 - loss: 1.4459 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 937ms/step - accuracy: 0.4204 - loss: 1.4065 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 792ms/step - accuracy: 0.4251 - loss: 1.4060 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 833ms/step - accuracy: 0.4068 - loss: 1.3804 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 790ms/step - accuracy: 0.4247 - loss: 1.3514 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 998ms/step - accuracy: 0.4229 - loss: 1.3619 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 801ms/step - accuracy: 0.4112 - loss: 1.3487 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 791ms/step - accuracy: 0.4318 - loss: 1.3691 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28738s\u001b[0m 282s/step - accuracy: 0.4251 - loss: 1.3495 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 776ms/step - accuracy: 0.4213 - loss: 1.3566 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 778ms/step - accuracy: 0.4254 - loss: 1.3155 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 3s/step - accuracy: 0.4260 - loss: 1.3234 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 774ms/step - accuracy: 0.4574 - loss: 1.3213 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 782ms/step - accuracy: 0.4035 - loss: 1.3159 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 772ms/step - accuracy: 0.4351 - loss: 1.3172 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 763ms/step - accuracy: 0.4326 - loss: 1.3061 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 8s/step - accuracy: 0.4471 - loss: 1.3282 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 764ms/step - accuracy: 0.4125 - loss: 1.3022 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 770ms/step - accuracy: 0.4331 - loss: 1.3157 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1230s\u001b[0m 12s/step - accuracy: 0.4232 - loss: 1.3153 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 763ms/step - accuracy: 0.4251 - loss: 1.3127 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1926s\u001b[0m 19s/step - accuracy: 0.4224 - loss: 1.3122 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 769ms/step - accuracy: 0.4281 - loss: 1.3089 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 766ms/step - accuracy: 0.4318 - loss: 1.3241 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1107s\u001b[0m 11s/step - accuracy: 0.4142 - loss: 1.3238 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 789ms/step - accuracy: 0.4268 - loss: 1.3123 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 800ms/step - accuracy: 0.4256 - loss: 1.3193 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - accuracy: 0.4289 - loss: 1.2981 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 878ms/step - accuracy: 0.4408 - loss: 1.3028 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 877ms/step - accuracy: 0.4357 - loss: 1.2983 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 863ms/step - accuracy: 0.4227 - loss: 1.3101 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 923ms/step - accuracy: 0.4258 - loss: 1.3258 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.4386 - loss: 1.3288 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 1s/step - accuracy: 0.4386 - loss: 1.3031 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 970ms/step - accuracy: 0.4056 - loss: 1.3038 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 996ms/step - accuracy: 0.4277 - loss: 1.3133 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.4186 - loss: 1.3001 - learning_rate: 0.0010\n",
      "Epoch 1/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 6s/step - accuracy: 0.6922 - loss: 0.7800 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m646s\u001b[0m 6s/step - accuracy: 0.8025 - loss: 0.5277 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 6s/step - accuracy: 0.8101 - loss: 0.4894 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 6s/step - accuracy: 0.8206 - loss: 0.4910 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 6s/step - accuracy: 0.8417 - loss: 0.4365 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 6s/step - accuracy: 0.8607 - loss: 0.3745 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 6s/step - accuracy: 0.8349 - loss: 0.4401 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 6s/step - accuracy: 0.8902 - loss: 0.3189 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m757s\u001b[0m 7s/step - accuracy: 0.8809 - loss: 0.3405 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 5s/step - accuracy: 0.8973 - loss: 0.2902 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 5s/step - accuracy: 0.8905 - loss: 0.3193 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 5s/step - accuracy: 0.8909 - loss: 0.2977 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 4s/step - accuracy: 0.9006 - loss: 0.3019 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 5s/step - accuracy: 0.8887 - loss: 0.3055 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 4s/step - accuracy: 0.9068 - loss: 0.2770 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 4s/step - accuracy: 0.9020 - loss: 0.2837 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 4s/step - accuracy: 0.8946 - loss: 0.3008 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 4s/step - accuracy: 0.9060 - loss: 0.2688 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 4s/step - accuracy: 0.9027 - loss: 0.2682 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 6s/step - accuracy: 0.9287 - loss: 0.2331 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers, callbacks\n",
    "import os\n",
    "\n",
    "# Paths for training and validation datasets\n",
    "train_dir = 'C:/DERM-AI PROJECT/Disease_Dataset_5_classes/train'\n",
    "\n",
    "\n",
    "# Step 1: Create data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)  # Only rescale for validation\n",
    "\n",
    "# Step 2: Load images in batches directly from disk\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),  # Match input size for pre-trained models\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Use Transfer Learning with EfficientNetB0\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base layers initially\n",
    "\n",
    "# Add custom layers on top\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Add callbacks\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=1e-6)\n",
    "checkpoint = callbacks.ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Step 6: Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "# Step 7: Unfreeze base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint]\n",
    ")\n",
    "\n",
    "# Step 8: Save the final model\n",
    "model.save('final_model_with_transfer_learning.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\kadam\\downloads\\derm-ai (2) (1)\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 493.7 kB/s eta 0:00:22\n",
      "   -- ------------------------------------- 0.8/11.0 MB 907.1 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/11.0 MB 907.1 kB/s eta 0:00:12\n",
      "   --- ------------------------------------ 1.0/11.0 MB 719.5 kB/s eta 0:00:14\n",
      "   --- ------------------------------------ 1.0/11.0 MB 719.5 kB/s eta 0:00:14\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.0 MB 952.0 kB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 5.2/11.0 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.0/11.0 MB 1.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 6.0/11.0 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 1.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.7 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/44.5 MB 32.8 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.3/44.5 MB 4.2 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 2.4/44.5 MB 4.1 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 2.9/44.5 MB 3.4 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.9/44.5 MB 3.4 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.9/44.5 MB 3.4 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 3.1/44.5 MB 2.3 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 4.7/44.5 MB 2.9 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 5.5/44.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 5.5/44.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 6.0/44.5 MB 2.8 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 6.8/44.5 MB 2.8 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 9.7/44.5 MB 3.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 9.7/44.5 MB 3.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 10.2/44.5 MB 3.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 13.1/44.5 MB 4.0 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 13.4/44.5 MB 3.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 13.9/44.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 13.9/44.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 14.7/44.5 MB 3.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 14.7/44.5 MB 3.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 14.9/44.5 MB 3.4 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 14.9/44.5 MB 3.4 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 14.9/44.5 MB 3.4 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 15.7/44.5 MB 3.0 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 15.7/44.5 MB 3.0 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 16.8/44.5 MB 3.1 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 17.6/44.5 MB 3.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 17.6/44.5 MB 3.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 17.8/44.5 MB 2.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 17.8/44.5 MB 2.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 18.1/44.5 MB 2.8 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 19.4/44.5 MB 2.9 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 20.2/44.5 MB 2.9 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 20.2/44.5 MB 2.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 21.2/44.5 MB 2.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 21.8/44.5 MB 2.8 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 22.5/44.5 MB 2.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 22.5/44.5 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 23.9/44.5 MB 2.9 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.1/44.5 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.1/44.5 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.1/44.5 MB 2.8 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.4/44.5 MB 2.7 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 2.7 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 2.7 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 27.3/44.5 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 28.8/44.5 MB 2.9 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 30.7/44.5 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 30.7/44.5 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 30.9/44.5 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 31.7/44.5 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 32.2/44.5 MB 3.0 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 33.0/44.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 34.3/44.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 34.3/44.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 34.3/44.5 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 34.6/44.5 MB 2.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 35.9/44.5 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 35.9/44.5 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 35.9/44.5 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 36.4/44.5 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 36.4/44.5 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 36.4/44.5 MB 2.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 37.0/44.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 38.5/44.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 38.8/44.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 38.8/44.5 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.4/44.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 40.4/44.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 40.4/44.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 41.9/44.5 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.3/44.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/44.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/44.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.8/44.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
